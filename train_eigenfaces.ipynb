{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as f\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_DIM = 112\n",
    "N_FACES = 1024\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "N_COLORS = 1\n",
    "DEVICE = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetrifyView(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(SymmetrifyView,self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self,x):\n",
    "        out = x.view((-1,*self.shape))\n",
    "        out += torch.flip(out, [3])\n",
    "        out = out / 2\n",
    "        return out\n",
    "    \n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View,self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self,x):\n",
    "        out = x.view((-1,*self.shape))\n",
    "        return out\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return (x - mean) / (std + 1e-6)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "    nn.Upsample(size=(IM_DIM,IM_DIM)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3*IM_DIM*IM_DIM, N_FACES,bias=False),\n",
    "    Normalize()\n",
    ")\n",
    "    \n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(N_FACES, 3*IM_DIM*IM_DIM,bias=False), \n",
    "    nn.Flatten(),\n",
    "    Normalize()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = glob.glob(\"../celeba_aligned_with_mtcnn/*.jpg\")\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,im_list):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.im_list = im_list\n",
    "    def __len__(self):\n",
    "        return len(self.im_list)\n",
    "    def __getitem__(self,i):\n",
    "        x_gray = torch.FloatTensor(np.array(f.to_grayscale(Image.open(self.im_list[i]),3))) / 255 - 0.5 \n",
    "        x_rgb = torch.FloatTensor(np.array(Image.open(self.im_list[i]))) / 255 - 0.5 \n",
    "        \n",
    "        return x_gray.permute(2,0,1), x_rgb.permute(2,0,1)\n",
    "    \n",
    "dataset = Dataset(im_list)\n",
    "print(\"# images:\", len(dataset))\n",
    "print(dataset[0][0].min())\n",
    "print(dataset[0][0].max())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(0.5 + dataset[10][0].permute(1,2,0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.to(DEVICE)\n",
    "decoder.to(DEVICE)\n",
    "opt = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()),lr=1e-3,weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "iters = 0\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(N_EPOCHS):\n",
    "    for X_gray, X_rgb in dataloader:\n",
    "        \n",
    "        iters += 1\n",
    "        X_gray = X_gray.to(DEVICE)\n",
    "        X_rgb = X_rgb.to(DEVICE)\n",
    "        X_rgb_sym = SymmetrifyView((3,IM_DIM,IM_DIM))(X_rgb.clone())\n",
    "        X_soft_sym = 0.5 * X_rgb + 0.5 * X_rgb_sym\n",
    "        \n",
    "        y = View((3,IM_DIM,IM_DIM))(decoder(encoder(X_gray)))\n",
    "        \n",
    "        noise = torch.normal(0,1,size=(X_rgb.shape[0],N_FACES)).to(DEVICE)\n",
    "        y_noise = View((3,IM_DIM,IM_DIM))(decoder(noise))\n",
    "        \n",
    "        loss = nn.MSELoss(\"mean\")(X_soft_sym,y) + 10 *  nn.MSELoss(\"mean\")(y_noise,X_rgb)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if iters % 50 == 0:\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            plt.figure(dpi=130)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(\"Input\")\n",
    "            plt.imshow(0.5 + X_soft_sym[0].permute(1,2,0).detach().cpu().numpy())\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(\"Output\")\n",
    "            plt.imshow(0.5 + y[0].permute(1,2,0).detach().cpu().numpy())\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.semilogy(train_loss)\n",
    "            plt.title(\"train loss\")\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            print(\"epoch:\",epoch)\n",
    "            torch.save(decoder,f\"eigenfaces_new.pt\")\n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "razzhigaev38",
   "language": "python",
   "name": "razzhigaev38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
